{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9f6c822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['OVA_Linear_model.pkl']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import joblib\n",
    "\n",
    "dataset = pd.read_csv('datasets\\story_emotion4.csv', encoding='ISO-8859-1')\n",
    "\n",
    "stopword = pd.read_csv('datasets\\stopwords_tl.csv')\n",
    "stopwords_set = set(stopword['stopword'])\n",
    "\n",
    "stemmer = pd.read_csv('datasets\\stem_tl.csv')\n",
    "word_to_stem = dict(zip(stemmer['word'], stemmer['stem']))\n",
    "\n",
    "replace_patterns = {\n",
    "    re.compile(r\"\\bngayo\\'y\\b\"): 'ngayon ay',\n",
    "    re.compile(r\"\\bhangga\\'t\\b\"): 'hanggang',\n",
    "    re.compile(r\"\\b\\'?y\\b\"): ' ay',\n",
    "    re.compile(r\"\\b\\'?t\\b\"): ' at',\n",
    "    re.compile(r\"\\b\\'?yan\\b\"): 'iyan',\n",
    "    re.compile(r\"\\b\\'?yo\\b\"): 'iyo',\n",
    "    re.compile(r\"\\b\\'?yon\\b\"): 'iyon',\n",
    "    re.compile(r\"\\b\\'?yun\\b\"): 'iyun',\n",
    "    re.compile(r\"\\b\\'?pagkat\\b\"): 'sapagkat',\n",
    "    re.compile(r\"\\b\\'?di\\b\"): 'hindi',\n",
    "    re.compile(r\"\\b\\'?kaw\\b\"): \"ikaw\",\n",
    "    re.compile(r\"\\b\\'?to\\b\"): 'ito',\n",
    "    re.compile(r\"\\b\\'?wag\\b\"): 'huwag',\n",
    "    re.compile(r\"\\bgano\\'n\\b\"): 'ganoon'\n",
    "}\n",
    "\n",
    "def data_preprocess(text, replace_patterns, word_to_stem, stopwords_set):\n",
    "    text = text.lower()\n",
    "\n",
    "    for pattern, replacement in replace_patterns.items():\n",
    "        text = pattern.sub(replacement, text)\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z0-9\\s?!]\", '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word_to_stem.get(word, word) for word in tokens if word.lower() not in stopwords_set])\n",
    "\n",
    "    return text\n",
    "\n",
    "dataset['text'] = dataset['text'].apply(data_preprocess, replace_patterns=replace_patterns, word_to_stem=word_to_stem, stopwords_set=stopwords_set)\n",
    "\n",
    "vectorizer = CountVectorizer()\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "\n",
    "X = dataset['text']\n",
    "Y = dataset['emotion']\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.2, random_state=42, stratify=Y)\n",
    "\n",
    "X_train_vectorized = vectorizer.fit_transform(X_train)\n",
    "X_test_vectorized = vectorizer.transform(X_test)\n",
    "\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_vectorized)\n",
    "X_test_tfidf = tfidf_transformer.transform(X_test_vectorized)\n",
    "\n",
    "svm = SVC(kernel='linear', C=0.1, random_state=42)\n",
    "classifier = OneVsRestClassifier(svm)\n",
    "\n",
    "classifier.fit(X_train_tfidf, Y_train)\n",
    "Y_pred = classifier.predict(X_test_tfidf)\n",
    "\n",
    "joblib.dump((classifier, vectorizer, tfidf_transformer), 'OVA_Linear_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89775e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text: nakakadire ka tingnan\n",
      "\n",
      "Emotion probabilities:\n",
      "fear: 16.78%\n",
      "anger: 16.09%\n",
      "joy: 16.69%\n",
      "sadness: 16.19%\n",
      "disgust: 18.64%\n",
      "surprise: 15.60%\n",
      "\n",
      "The predicted emotion for the input text is: disgust\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from langdetect import detect\n",
    "\n",
    "# Load the trained model and vectorizer from the file\n",
    "model_components = joblib.load('OVA_Linear_model.pkl')\n",
    "SVM_model, vectorizer, tfidf_transformer = model_components\n",
    "\n",
    "# Define the same preprocessing functions and data structures used during training\n",
    "stopword = pd.read_csv('datasets\\stopwords_tl.csv')\n",
    "stopwords_set = set(stopword['stopword'])\n",
    "\n",
    "stemmer = pd.read_csv('datasets\\stem_tl.csv')\n",
    "word_to_stem = dict(zip(stemmer['word'], stemmer['stem']))\n",
    "\n",
    "replace_patterns = {\n",
    "    re.compile(r\"\\bngayo\\'y\\b\"): 'ngayon ay',\n",
    "    re.compile(r\"\\bhangga\\'t\\b\"): 'hanggang',\n",
    "    re.compile(r\"\\b\\'?y\\b\"): ' ay',\n",
    "    re.compile(r\"\\b\\'?t\\b\"): ' at',\n",
    "    re.compile(r\"\\b\\'?yan\\b\"): 'iyan',\n",
    "    re.compile(r\"\\b\\'?yo\\b\"): 'iyo',\n",
    "    re.compile(r\"\\b\\'?yon\\b\"): 'iyon',\n",
    "    re.compile(r\"\\b\\'?yun\\b\"): 'iyun',\n",
    "    re.compile(r\"\\b\\'?pagkat\\b\"): 'sapagkat',\n",
    "    re.compile(r\"\\b\\'?di\\b\"): 'hindi',\n",
    "    re.compile(r\"\\b\\'?kaw\\b\"): \"ikaw\",\n",
    "    re.compile(r\"\\b\\'?to\\b\"): 'ito',\n",
    "    re.compile(r\"\\b\\'?wag\\b\"): 'huwag',\n",
    "    re.compile(r\"\\bgano\\'n\\b\"): 'ganoon'\n",
    "}\n",
    "\n",
    "foul_words = {\n",
    "    'gago','gaga', 'puta', 'pakyu','pakshet','buang','walanghiya ','piste','lintik',\n",
    "    'putangina','tarantado','punyeta','bwisit','kupal','hinyupak', 'tanga', 'tangina','bobo','boba','putragis', 'syet'\n",
    "}\n",
    "\n",
    "class_names = {\n",
    "    1: 'fear',\n",
    "    2: 'anger',\n",
    "    3: 'joy',\n",
    "    4: 'sadness',\n",
    "    5: 'disgust',\n",
    "    6: 'surprise'\n",
    "}\n",
    "def data_preprocess(text, replace_patterns, word_to_stem, stopwords_set):\n",
    "    text = text.lower()\n",
    "\n",
    "    for pattern, replacement in replace_patterns.items():\n",
    "        text = pattern.sub(replacement, text)\n",
    "\n",
    "    text = re.sub(\"[^a-zA-Z0-9\\s?!]\", '', text)\n",
    "    tokens = word_tokenize(text)\n",
    "    text = ' '.join([word_to_stem.get(word, word) for word in tokens if word.lower() not in stopwords_set])\n",
    "\n",
    "    return text\n",
    "\n",
    "user_input = input(\"Enter a text: \")\n",
    "\n",
    "try:\n",
    "    lang = detect(user_input)\n",
    "except Exception as e:\n",
    "    lang = None\n",
    "\n",
    "if lang.lower() != 'tl':\n",
    "    print(\"Error: The system currently only accepts Tagalog words.\")\n",
    "else:\n",
    "    user_input_processed = data_preprocess(user_input, replace_patterns, word_to_stem, stopwords_set)\n",
    "\n",
    "    if any(word in user_input_processed.lower() for word in foul_words):\n",
    "        print(\"Warning: There are words that are not appropriate for children to read.\")\n",
    "    else:\n",
    "        user_input_vectorized = vectorizer.transform([user_input_processed])\n",
    "        user_input_tfidf = tfidf_transformer.transform(user_input_vectorized)\n",
    "\n",
    "        decision_values = SVM_model.decision_function(user_input_tfidf)[0]\n",
    "\n",
    "        exp_values = np.exp(decision_values - np.max(decision_values))  \n",
    "        probabilities = exp_values / exp_values.sum(axis=0, keepdims=True)\n",
    "\n",
    "        emotion_probabilities_dict = {class_names[i+1]: probability * 100 for i, probability in enumerate(probabilities)}\n",
    "\n",
    "        for emotion in class_names.values():\n",
    "            if emotion not in emotion_probabilities_dict:\n",
    "                emotion_probabilities_dict[emotion] = 0.0\n",
    "\n",
    "        print(\"\\nEmotion probabilities:\")\n",
    "        for emotion, percentage in emotion_probabilities_dict.items():\n",
    "            print(f\"{emotion}: {percentage:.2f}%\")\n",
    "\n",
    "        max_emotion = max(emotion_probabilities_dict, key=emotion_probabilities_dict.get)\n",
    "\n",
    "        print(f\"\\nThe predicted emotion for the input text is: {max_emotion}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671d91d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710262a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
